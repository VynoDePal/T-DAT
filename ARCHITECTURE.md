# Architecture Technique - CRYPTO VIZ

Ce document dÃ©taille l'architecture technique du systÃ¨me CRYPTO VIZ.

## ğŸ“ Vue d'Ensemble de l'Architecture

### Diagramme de Flux de DonnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SOURCES DE DONNÃ‰ES                          â”‚
â”‚                    (Serveur Kafka Externe)                      â”‚
â”‚                   20.199.136.163:9092                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚                 â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ rawticker â”‚    â”‚ rawtrade  â”‚    â”‚rawarticle â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                 â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                                 â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  SPARK JOB 1   â”‚            â”‚   SPARK JOB 2   â”‚
    â”‚  Ingestion     â”‚            â”‚   Analytics     â”‚
    â”‚  - Ticker      â”‚            â”‚   - Sentiment   â”‚
    â”‚  - Trade       â”‚            â”‚   - Prediction  â”‚
    â”‚  - Article     â”‚            â”‚                 â”‚
    â”‚  - Alert       â”‚            â”‚                 â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚ TimescaleDB â”‚
                    â”‚ (PostgreSQL)â”‚
                    â”‚  Hypertablesâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚   Django    â”‚
                    â”‚  REST API   â”‚
                    â”‚ (+ SQLite)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
         â”‚   HTTP API  â”‚      â”‚  WebSocket  â”‚
         â”‚   (REST)    â”‚      â”‚  (Channels) â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚                     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚  Frontend   â”‚
                    â”‚ (React/Vue) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Composants DÃ©taillÃ©s

### 1. Sources de DonnÃ©es (Kafka Topics)

#### rawticker
**Fonction** : Prix en temps rÃ©el des crypto-monnaies

**Format** :
```json
{
  "pair": "BTC/USD",
  "last": 34000.12,
  "bid": 33990.00,
  "ask": 34010.00,
  "volume_24h": 1200.5,
  "timestamp": 1764310291
}
```

**FrÃ©quence** : Temps rÃ©el (plusieurs fois par seconde)

#### rawtrade
**Fonction** : Transactions individuelles d'achat/vente

**Format** :
```json
{
  "pair": "ETH/USD",
  "price": 2400.5,
  "volume": 2.1,
  "timestamp": 1764310292,
  "side": "b"
}
```

**FrÃ©quence** : Temps rÃ©el (Ã  chaque transaction)

#### rawarticle
**Fonction** : Articles de presse crypto avec analyse de sentiment

**Format** :
```json
{
  "id": "cointelegraph_1764313285",
  "title": "Bitcoiners accuse JPMorgan...",
  "url": "https://cointelegraph.com/news/...",
  "website": "cointelegraph.com",
  "content": {"summary": "..."},
  "cryptocurrencies_mentioned": ["BTC","ETH"],
  "sentiment": {
    "score": 0.993,
    "label": "positive"
  }
}
```

**FrÃ©quence** : Quasi temps rÃ©el (scraping pÃ©riodique)

#### rawalert
**Fonction** : Alertes de variation de prix significative

**Format** :
```json
{
  "pair": "BTC/USD",
  "last": 34000,
  "change": 1.2,
  "threshold": 1,
  "timestamp": 1764310293
}
```

**FrÃ©quence** : Ã‰vÃ©nementiel (quand seuil dÃ©passÃ©)

---

### 2. Couche de Traitement (Apache Spark)

#### Job 1 : Ingestion (`kafka_to_timescale.py`)

**ResponsabilitÃ©s** :
- Consommer les 4 topics Kafka
- Parser et valider les donnÃ©es JSON
- Transformer les timestamps
- Ã‰crire dans TimescaleDB via JDBC

**Configuration** :
- Mode : Structured Streaming
- Checkpoint : `/tmp/spark_checkpoints/`
- Trigger : Processing time (micro-batches)

**Tables de destination** :
- `ticker_data`
- `trade_data`
- `article_data`
- `alert_data`

#### Job 2 : Analytics (`sentiment_prediction_job.py`)

**ResponsabilitÃ©s** :
- Analyser le sentiment agrÃ©gÃ© par crypto
- GÃ©nÃ©rer des prÃ©dictions de prix
- Calculer des mÃ©triques avancÃ©es

**Algorithmes** :
- Sentiment : AgrÃ©gation par fenÃªtre temporelle (5 min)
- PrÃ©diction : Moyenne mobile + intervalles de confiance

**Tables de destination** :
- `sentiment_data`
- `prediction_data`

**FenÃªtres temporelles** :
- FenÃªtre de traitement : 5 minutes
- Watermark : 10 minutes

---

### 3. Couche de Stockage

#### TimescaleDB (SÃ©ries Temporelles)

**RÃ´le** : Stockage optimisÃ© des donnÃ©es temporelles

**Tables hypertables** :

| Table | Description | Index Principaux | RÃ©tention |
|-------|-------------|------------------|-----------|
| `ticker_data` | Prix temps rÃ©el | (pair, timestamp) | 90 jours |
| `trade_data` | Transactions | (pair, timestamp), (side) | 90 jours |
| `article_data` | Articles | (timestamp), (cryptos), (sentiment) | 90 jours |
| `alert_data` | Alertes | (pair, timestamp), (type) | 90 jours |
| `sentiment_data` | Sentiment agrÃ©gÃ© | (crypto, timestamp) | 90 jours |
| `prediction_data` | PrÃ©dictions | (crypto, timestamp), (model) | 90 jours |

**Vues matÃ©rialisÃ©es** :
- `sentiment_hourly` : Sentiment moyen horaire
- `ticker_ohlc_hourly` : OHLC (Open/High/Low/Close) horaire

**Optimisations** :
- Compression automatique des chunks anciens
- Politiques de rÃ©tention (90 jours)
- AgrÃ©gations continues
- Index optimisÃ©s pour requÃªtes temporelles

#### SQLite (MÃ©tadonnÃ©es Django)

**RÃ´le** : Stockage lÃ©ger pour donnÃ©es non critiques

**Tables** :
- `crypto_configuration` : Configuration des cryptos suivies
- `visualization_parameters` : ParamÃ¨tres utilisateur
- `data_cache` : Cache temporaire de rÃ©sultats

**Pourquoi SQLite ?**
- âœ… Suffisant pour mÃ©tadonnÃ©es
- âœ… Pas de dÃ©pendance externe
- âœ… Configuration simple
- âŒ Ne gÃ¨re PAS les donnÃ©es temporelles

---

### 4. Couche API (Django REST Framework)

#### Architecture Django

```
crypto_viz/          # Projet Django
â”œâ”€â”€ settings.py      # Configuration (SQLite + TimescaleDB)
â”œâ”€â”€ urls.py          # Routes principales
â””â”€â”€ wsgi.py          # WSGI application

api/                 # Application API
â”œâ”€â”€ models.py        # ModÃ¨les SQLite (mÃ©tadonnÃ©es)
â”œâ”€â”€ serializers.py   # Serializers DRF
â”œâ”€â”€ views.py         # Vues API REST
â”œâ”€â”€ timescale_client.py  # Client TimescaleDB
â””â”€â”€ urls.py          # Routes API
```

#### Endpoints Principaux

**Configuration (SQLite)** :
```
GET    /api/v1/config/crypto/
POST   /api/v1/config/crypto/
GET    /api/v1/config/visualization/
```

**DonnÃ©es Historiques (TimescaleDB)** :
```
GET    /api/v1/sentiment/{symbol}/historique/
GET    /api/v1/prediction/{symbol}/historique/
GET    /api/v1/ticker/{pair}/historique/
GET    /api/v1/trade/{pair}/historique/
GET    /api/v1/article/historique/
GET    /api/v1/alert/historique/
```

**ParamÃ¨tres de requÃªte** :
- `periode` : 1h, 24h, 7d, 30d
- `date_debut` : Date ISO 8601
- `date_fin` : Date ISO 8601

#### StratÃ©gie de Connexion

**SQLite** (via ORM Django) :
```python
# UtilisÃ© par dÃ©faut pour les modÃ¨les Django
CryptoConfiguration.objects.all()
```

**TimescaleDB** (connexion directe) :
```python
# Via psycopg2 sans ORM
from api.timescale_client import timescale_client
data = timescale_client.get_sentiment_history('BTC', '24h')
```

---

### 5. Temps RÃ©el (WebSocket)

**Option 1** : API WebSocket Externe (existante)
- URL : `ws://20.199.136.163:8000/ws/raw-ticker`
- Lecture directe depuis Kafka
- âœ… RecommandÃ©e si performante

**Option 2** : Django Channels (Ã  implÃ©menter)
- Consumer Django s'abonne Ã  Kafka
- Retransmet via Channel Layer (Redis)
- Permet logique mÃ©tier supplÃ©mentaire

---

## ğŸ”„ Flux de DonnÃ©es DÃ©taillÃ©

### Exemple : Prix BTC/USD

1. **Kafka** : Message publiÃ© sur `rawticker`
   ```json
   {"pair": "BTC/USD", "last": 34000, ...}
   ```

2. **Spark Ingestion** : 
   - Lit depuis Kafka
   - Parse JSON
   - Valide les donnÃ©es
   - Ã‰crit dans `ticker_data`

3. **Spark Analytics** :
   - AgrÃ¨ge sur fenÃªtre 5 min
   - Calcule prÃ©diction (moyenne mobile)
   - Ã‰crit dans `prediction_data`

4. **TimescaleDB** :
   - Stocke dans hypertable
   - Compression automatique
   - Index pour requÃªtes rapides

5. **Django API** :
   - Client frontend requÃªte `/api/v1/ticker/BTC/USD/historique/?periode=1h`
   - Django interroge TimescaleDB
   - Retourne JSON sÃ©rialisÃ©

6. **Frontend** :
   - Affiche graphique des prix
   - Met Ã  jour en temps rÃ©el via WebSocket

---

## ğŸš€ Performance et ScalabilitÃ©

### Optimisations Actuelles

**TimescaleDB** :
- Chunks de 7 jours
- Compression aprÃ¨s 7 jours
- RÃ©tention automatique (90 jours)
- Index sur colonnes frÃ©quemment requÃªtÃ©es

**Spark** :
- Micro-batches pour faible latence
- Checkpointing pour reprise sur erreur
- Watermarks pour gestion des donnÃ©es tardives

**Django** :
- Pagination (100 items par page)
- Cache potentiel avec Redis
- Connexion pooling pour TimescaleDB

### Limites et ScalabilitÃ©

**Goulots d'Ã©tranglement potentiels** :

1. **Ã‰criture TimescaleDB** :
   - Limitation : ~10k inserts/sec (single node)
   - Solution : Cluster TimescaleDB + sharding

2. **RequÃªtes API Django** :
   - Limitation : ~100 req/sec (single instance)
   - Solution : Load balancer + instances multiples

3. **Spark Processing** :
   - Limitation : DÃ©pend des ressources (local[*])
   - Solution : Cluster Spark (YARN, Kubernetes)

**Recommandations pour Production** :

- TimescaleDB : Cluster multi-nodes
- Django : DÃ©ploiement multi-instances (Kubernetes)
- Spark : Cluster dÃ©diÃ©
- Cache : Redis pour rÃ©sultats frÃ©quents
- CDN : Pour assets frontend

---

## ğŸ”’ SÃ©curitÃ©

### ImplÃ©mentÃ©

- Variables d'environnement pour credentials
- CORS configurÃ© (Ã  restreindre en prod)
- SQLite pour donnÃ©es non sensibles
- Validation des entrÃ©es API

### Ã€ ImplÃ©menter

- [ ] Authentification JWT
- [ ] Rate limiting
- [ ] HTTPS obligatoire
- [ ] Secrets management (Vault)
- [ ] Audit logs

---

## ğŸ“Š Monitoring et Logs

### Logs Actuels

- Django : `logs/django.log`
- Spark Ingestion : `logs/spark_ingestion.log`
- Spark Analytics : `logs/spark_analytics.log`
- TimescaleDB : Docker logs

### MÃ©triques RecommandÃ©es

**Application** :
- Nombre de requÃªtes API
- Latence des requÃªtes
- Taux d'erreur

**Base de donnÃ©es** :
- Nombre de rows par table
- Taille des chunks TimescaleDB
- Temps de requÃªte moyen

**Spark** :
- Records traitÃ©s/sec
- Lag Kafka
- Taux d'Ã©chec des batches

### Outils RecommandÃ©s

- **Prometheus** : MÃ©triques
- **Grafana** : Dashboards
- **ELK Stack** : Logs centralisÃ©s
- **Spark UI** : Monitoring Spark

---

## ğŸ§ª Tests

### Types de Tests

**Tests Unitaires** :
- ModÃ¨les Django
- Serializers
- Fonctions utilitaires

**Tests d'IntÃ©gration** :
- APIs REST
- Client TimescaleDB
- Jobs Spark (mini-batches)

**Tests de Performance** :
- Charge API (Locust, JMeter)
- Ingestion Spark (volumes)
- RequÃªtes TimescaleDB

### Ã€ ImplÃ©menter

```bash
# Django
python manage.py test

# Spark (avec pytest)
pytest spark_jobs/tests/
```

---

## ğŸ“š RÃ©fÃ©rences

- [Django Documentation](https://docs.djangoproject.com/)
- [Django REST Framework](https://www.django-rest-framework.org/)
- [Apache Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [TimescaleDB Documentation](https://docs.timescale.com/)
- [Kafka Python Client](https://kafka-python.readthedocs.io/)

---

**Version** : 1.0.0  
**Date** : Novembre 2024  
**Auteur** : CRYPTO VIZ Team
