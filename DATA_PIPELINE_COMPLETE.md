# Pipeline de Donn√©es Crypto - Op√©rationnel

## ‚úÖ Statut: **PRODUCTION READY**

Le pipeline complet de donn√©es crypto est maintenant **100% fonctionnel** et traite des donn√©es en temps r√©el !

---

## Statistiques Actuelles

**Donn√©es en temps r√©el dans TimescaleDB:**
- **Tickers (prix)**: 176+ entr√©es et augmentation constante
- **Trades (transactions)**: 903+ entr√©es et augmentation constante
- **Articles**: En cours de collecte toutes les 5 minutes

**Processus actifs:**
- ‚úÖ Producteur Kraken WebSocket (rawticker, rawtrade, rawalert)
- ‚úÖ Scraper d'articles crypto (rawarticle)
- ‚úÖ Spark Ingestion Job (Kafka ‚Üí TimescaleDB)
- ‚úÖ Spark Analytics Job (sentiment & pr√©dictions)

---

## Architecture Compl√®te

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   CRYPTO VIZ PIPELINE                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

[PRODUCTEURS DE DONN√âES]
   ‚îÇ
   ‚îú‚îÄ  Kraken WebSocket
   ‚îÇ    ‚îî‚îÄ Connexion WSS √† Kraken
   ‚îÇ    ‚îî‚îÄ 8 paires crypto (BTC, ETH, SOL, ADA, etc.)
   ‚îÇ    ‚îî‚îÄ Donn√©es ticker + trades en temps r√©el
   ‚îÇ
   ‚îú‚îÄ  Article Scraper
   ‚îÇ    ‚îî‚îÄ 5 sources RSS (CoinDesk, Cointelegraph, etc.)
   ‚îÇ    ‚îî‚îÄ Scraping toutes les 5 minutes
   ‚îÇ    ‚îî‚îÄ Extraction contenu + tags crypto
   ‚îÇ
   ‚ñº
[KAFKA TOPICS]
   ‚îÇ
   ‚îú‚îÄ rawticker (3 partitions)
   ‚îú‚îÄ rawtrade (3 partitions)
   ‚îú‚îÄ rawarticle (3 partitions)
   ‚îî‚îÄ rawalert (3 partitions)
   ‚îÇ
   ‚ñº
[SPARK STREAMING]
   ‚îÇ
   ‚îú‚îÄ Job Ingestion
   ‚îÇ    ‚îî‚îÄ Parse JSON Kafka
   ‚îÇ    ‚îî‚îÄ Transformations
   ‚îÇ    ‚îî‚îÄ Validation timestamps
   ‚îÇ
   ‚îú‚îÄ Job Analytics
   ‚îÇ    ‚îî‚îÄ Analyse de sentiment
   ‚îÇ    ‚îî‚îÄ Pr√©dictions ML
   ‚îÇ    ‚îî‚îÄ Agr√©gations
   ‚îÇ
   ‚ñº
[TIMESCALEDB]
   ‚îÇ
   ‚îú‚îÄ ticker_data (hypertable, 90j r√©tention)
   ‚îú‚îÄ trade_data (hypertable, 30j r√©tention)
   ‚îú‚îÄ article_data (hypertable, 180j r√©tention)
   ‚îî‚îÄ prediction_data (hypertable, 365j r√©tention)
   ‚îÇ
   ‚ñº
[DJANGO REST API]
   ‚îÇ
   ‚îî‚îÄ Endpoints visualisation
   ‚îî‚îÄ WebSocket temps r√©el
   ‚îî‚îÄ Interface Admin
```

---

## D√©marrage du Syst√®me

### **1. D√©marrage Complet (Tout en Une Fois)**

```bash
cd /home/kevyn-odjo/Documents/T-DAT

# D√©marrer tous les services de base
./scripts/start_all.sh

# D√©marrer les producteurs de donn√©es
./data_producers/start_producers.sh
```

**Ce qui d√©marre:**
1. ‚úÖ Zookeeper + Kafka (avec cr√©ation auto des topics)
2. ‚úÖ TimescaleDB + Redis
3. ‚úÖ Django API (migrations automatiques)
4. ‚úÖ Spark Jobs (Ingestion + Analytics)
5. ‚úÖ Producteurs Kraken + Articles

### **2. D√©marrage S√©lectif**

```bash
# Seulement l'infrastructure
./scripts/start_all.sh

# Seulement les producteurs
./data_producers/start_producers.sh

# Red√©marrer seulement Spark
./scripts/restart_spark.sh
```

---

## V√©rification du Syst√®me

### **V√©rifier Kafka**

```bash
# Lister les topics
docker exec crypto_viz_kafka kafka-topics --bootstrap-server kafka:29092 --list

# Consommer des messages en temps r√©el
docker exec -it crypto_viz_kafka kafka-console-consumer \
  --bootstrap-server kafka:29092 \
  --topic rawticker \
  --from-beginning

# Statistiques des topics
docker exec crypto_viz_kafka kafka-topics \
  --bootstrap-server kafka:29092 \
  --describe --topic rawticker
```

### **V√©rifier TimescaleDB**

```bash
# Se connecter √† la base
docker exec -it crypto_viz_timescaledb psql -U postgres -d crypto_viz_ts

# Requ√™tes SQL
SELECT COUNT(*) FROM ticker_data;
SELECT COUNT(*) FROM trade_data;

# Derni√®res donn√©es
SELECT pair, last, timestamp 
FROM ticker_data 
ORDER BY timestamp DESC 
LIMIT 10;

# Donn√©es par paire
SELECT pair, COUNT(*) as total, MAX(timestamp) as last_update
FROM ticker_data
GROUP BY pair
ORDER BY total DESC;
```

### **V√©rifier les Logs**

```bash
# Producteur Kraken
tail -f logs/kraken_producer.log

# Scraper Articles
tail -f logs/article_scraper.log

# Spark Ingestion
tail -f logs/spark_ingestion.log

# Spark Analytics
tail -f logs/spark_analytics.log

# Django API
tail -f logs/django.log
```

### **V√©rifier l'API Django**

```bash
# Health check
curl http://localhost:8000/api/v1/health/

# Exemple de donn√©es
curl http://localhost:8000/api/v1/config/crypto/
```

---

## üõë Arr√™t du Syst√®me

```bash
# Arr√™ter les producteurs
./data_producers/stop_producers.sh

# Arr√™ter tout le reste
./scripts/stop_all.sh
```

---

## Composants Cr√©√©s

### **1. Producteurs de Donn√©es**

**`data_producers/kraken_producer.py`**
- WebSocket Kraken temps r√©el
- 8 paires crypto
- D√©tection alertes (changements > 1%)
- Topics: rawticker, rawtrade, rawalert

**`data_producers/article_scraper.py`**
- 5 sources RSS crypto
- Scraping p√©riodique (5 min)
- Extraction contenu + tags
- Topic: rawarticle

**`data_producers/requirements.txt`**
- confluent-kafka (compatible Python 3.13)
- websocket-client, feedparser, beautifulsoup4

**Scripts de gestion:**
- `start_producers.sh` - D√©marrage
- `stop_producers.sh` - Arr√™t

### **2. Configuration Kafka Locale**

**`docker-compose.yml`**
- Zookeeper (port 2181)
- Kafka (ports 9092, 29092)
- Auto-cr√©ation topics d√©sactiv√©e

**`scripts/create_kafka_topics.sh`**
- Cr√©ation automatique: rawticker, rawtrade, rawarticle, rawalert
- 3 partitions par topic
- Retry logic si Kafka pas pr√™t

### **3. Jobs Spark Modifi√©s**

**`spark_jobs/kafka_to_timescale.py`**
- Utilise `from_unixtime()` pour timestamps
- Parse JSON avec sch√©mas stricts
- √âcriture JDBC vers TimescaleDB

**`spark_jobs/schemas.py`**
- Timestamp: DoubleType (secondes Unix)
- Sch√©mas mis √† jour pour tous les topics

**`scripts/restart_spark.sh`**
- Red√©marrage propre des jobs
- Nettoyage checkpoints

---

## R√©solution de Probl√®mes

### **Kafka ne d√©marre pas**

```bash
# Augmenter le d√©lai dans start_all.sh
sleep 60  # Au lieu de 40s

# V√©rifier les logs
docker logs crypto_viz_kafka
```

### **Pas de donn√©es dans TimescaleDB**

```bash
# V√©rifier que Spark tourne
ps aux | grep kafka_to_timescale

# V√©rifier les logs Spark
tail -100 logs/spark_ingestion.log

# Red√©marrer Spark
./scripts/restart_spark.sh
```

### **Producteurs crashent**

```bash
# Logs producteurs
tail -50 logs/kraken_producer.log
tail -50 logs/article_scraper.log

# R√©installer d√©pendances
cd data_producers
rm -rf venv
./start_producers.sh
```

### **Erreur Python 3.13 avec kafka-python**

‚úÖ **R√âSOLU** - Utilise `confluent-kafka` au lieu de `kafka-python`

### **Timestamps NULL dans TimescaleDB**

‚úÖ **R√âSOLU** - Utilise `from_unixtime()` dans Spark au lieu de `to_timestamp()`

---

## Exemple de Donn√©es

### **Ticker Data (Prix)**

```json
{
  "pair": "XBT/USD",
  "last": 89800.10,
  "bid": 89799.90,
  "ask": 89800.00,
  "volume_24h": 2229.43,
  "timestamp": 1768933325.16,
  "pct_change": 0.02
}
```

### **Trade Data (Transactions)**

```json
{
  "pair": "ETH/USD",
  "price": 3003.39,
  "volume": 0.1963,
  "timestamp": 1768933326.45,
  "side": "b"
}
```

### **Article Data**

```json
{
  "title": "Bitcoin hits new high",
  "url": "https://...",
  "source": "CoinDesk",
  "summary": "...",
  "content": "...",
  "published_at": 1768933000,
  "scraped_at": 1768933325,
  "tags": ["bitcoin", "btc", "crypto", "trading"]
}
```

---

## Prochaines √âtapes Recommand√©es

1. **Monitoring & Alertes**
   - Ajouter Prometheus/Grafana
   - Alertes si producteurs down
   - M√©triques Kafka (lag, throughput)

2. **Optimisations**
   - Tuning Kafka (retention, compression)
   - Augmenter partitions si besoin
   - Cache Redis pour API

3. **Features**
   - Dashboard temps r√©el (WebSocket)
   - Backtesting avec donn√©es historiques
   - ML models avanc√©s (LSTM, Transformers)

4. **Production**
   - Docker Compose production-ready
   - Secrets management (Vault)
   - CI/CD pipeline
   - Backup automatiques TimescaleDB

---

## Documentation Associ√©e

- `KAFKA_LOCAL_SETUP.md` - Configuration Kafka d√©taill√©e
- `INSTALLATION.md` - Installation initiale
- `QUICKSTART.md` - D√©marrage rapide
- `TROUBLESHOOTING.md` - R√©solution de probl√®mes
