# üîß Guide de D√©pannage - CRYPTO VIZ

## Probl√®me : Erreur psycopg2-binary avec Python 3.13

### ‚ùå Erreur rencontr√©e

```
fatal error: libpq-fe.h: Aucun fichier ou dossier de ce nom
ERROR: Failed building wheel for psycopg2-binary
```

### üîç Cause du probl√®me

**Python 3.13** est tr√®s r√©cent et `psycopg2-binary==2.9.9` n'a pas de wheels pr√©-compil√©s pour cette version. Le syst√®me essaie donc de compiler depuis la source, mais il manque les headers PostgreSQL.

### ‚úÖ Solutions

#### Solution 1 : Mettre √† jour psycopg2-binary (RECOMMAND√â) ‚ú®

**Avantage** : Simple et rapide, pas de d√©pendances syst√®me suppl√©mentaires

La version `2.9.11` inclut des wheels pr√©-compil√©s pour Python 3.13.

```bash
# Les fichiers requirements.txt ont d√©j√† √©t√© mis √† jour vers 2.9.11
cd /home/kevyn-odjo/Documents/T-DAT

# Relancer l'installation
./scripts/setup_project.sh
```

#### Solution 2 : Installer les d√©pendances PostgreSQL

**Avantage** : Permet de compiler depuis la source (utile pour des versions sp√©cifiques)

```bash
# Installer les headers PostgreSQL
sudo apt-get update
sudo apt-get install -y libpq-dev python3-dev

# Puis relancer l'installation
cd /home/kevyn-odjo/Documents/T-DAT
./scripts/setup_project.sh
```

#### Solution 3 : Installation manuelle dans l'environnement virtuel

```bash
cd /home/kevyn-odjo/Documents/T-DAT/crypto_viz_backend
source venv/bin/activate

# Installer psycopg2-binary 2.9.11 directement
pip install psycopg2-binary==2.9.11

# Puis installer le reste
pip install -r requirements.txt
```

#### Solution 4 : Utiliser psycopg3 (alternative moderne)

**Note** : N√©cessite des modifications du code

`psycopg` (version 3) est le successeur moderne de `psycopg2` avec un meilleur support Python 3.13.

```bash
# Modifier requirements.txt
# Remplacer psycopg2-binary par psycopg[binary]

# Dans requirements.txt:
psycopg[binary]==3.1.19
psycopg[pool]==3.1.19
```

**Modifications de code n√©cessaires** :

```python
# Ancien (psycopg2):
import psycopg2
from psycopg2.extras import RealDictCursor

# Nouveau (psycopg3):
import psycopg
from psycopg.rows import dict_row
```

---

## Autres Probl√®mes Courants

### Erreur : "Port 15432 or 6380 already in use"

**Cause** : Un autre service utilise les ports Docker

**Solutions** :

```bash
# V√©rifier quel processus utilise le port
sudo lsof -i :15432
sudo lsof -i :6380

# Si n√©cessaire, changer les ports dans docker-compose.yml
ports:
  - "15433:5432"  # TimescaleDB sur port externe diff√©rent
  - "6381:6379"  # Redis sur port externe diff√©rent
```

**Note** : Les ports Docker sont configur√©s sur 15432/6380 pour √©viter les conflits avec PostgreSQL/Redis locaux.

### Erreur : "Port 8000 already in use"

**Cause** : Un autre serveur web utilise le port 8000

**Solutions** :

```bash
# Trouver le processus
lsof -i :8000

# Tuer le processus
kill -9 <PID>

# Ou utiliser un autre port
python manage.py runserver 0.0.0.0:8001
```

### Erreur : "Kafka connection timeout"

**Cause** : Le serveur Kafka n'est pas accessible

**Solutions** :

```bash
# Tester la connectivit√©
ping 20.199.136.163

# Tester le port Kafka
telnet 20.199.136.163 9092
# ou
nc -zv 20.199.136.163 9092

# V√©rifier avec le script de test
python3 scripts/test_kafka_connection.py
```

**Causes possibles** :
- Firewall bloquant le port 9092
- VPN requis pour acc√©der au serveur
- Serveur Kafka hors ligne

### Erreur : "TimescaleDB connection refused"

**Cause** : TimescaleDB n'est pas d√©marr√© ou pas pr√™t

**Solutions** :

```bash
# V√©rifier l'√©tat des conteneurs
docker compose ps

# Red√©marrer TimescaleDB
docker compose restart timescaledb

# Voir les logs
docker logs crypto_viz_timescaledb

# Attendre que la base soit pr√™te
docker exec crypto_viz_timescaledb pg_isready -U postgres
```

### Erreur : Java non trouv√© (pour Spark)

**Cause** : Java n'est pas install√© ou pas dans le PATH

**Solutions** :

```bash
# V√©rifier Java
java -version

# Installer Java 11 (Ubuntu/Debian)
sudo apt-get update
sudo apt-get install -y openjdk-11-jdk

# Installer Java 11 (Fedora/RHEL)
sudo dnf install java-11-openjdk-devel

# D√©finir JAVA_HOME
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH
```

### Erreur : "ModuleNotFoundError: No module named 'pyspark'"

**Cause** : Environnement virtuel non activ√© ou d√©pendances non install√©es

**Solutions** :

```bash
cd /home/kevyn-odjo/Documents/T-DAT/spark_jobs

# Activer l'environnement virtuel
source venv/bin/activate

# R√©installer les d√©pendances
pip install -r requirements.txt
```

### Erreur : Django migrations √©chouent

**Cause** : Base de donn√©es corrompue ou migrations conflictuelles

**Solutions** :

```bash
cd crypto_viz_backend
source venv/bin/activate

# Supprimer la base SQLite
rm db.sqlite3

# Supprimer les fichiers de migration (sauf __init__.py)
find api/migrations -name "*.py" ! -name "__init__.py" -delete

# Recr√©er les migrations
python manage.py makemigrations
python manage.py migrate
```

### Erreur : "Docker daemon not running"

**Cause** : Docker n'est pas d√©marr√©

**Solutions** :

```bash
# D√©marrer Docker (Linux)
sudo systemctl start docker

# Activer Docker au d√©marrage
sudo systemctl enable docker

# V√©rifier l'√©tat
sudo systemctl status docker
```

### Erreur : Permissions insuffisantes pour Docker

**Cause** : L'utilisateur n'est pas dans le groupe docker

**Solutions** :

```bash
# Ajouter l'utilisateur au groupe docker
sudo usermod -aG docker $USER

# Se d√©connecter et se reconnecter pour appliquer

# Ou red√©marrer la session
newgrp docker

# V√©rifier
docker ps
```

### Erreur : Spark "OutOfMemoryError"

**Cause** : M√©moire insuffisante allou√©e √† Spark

**Solutions** :

```bash
# Modifier la configuration Spark dans config.py
# Ajouter ces options :

spark = SparkSession.builder \
    .config("spark.driver.memory", "4g") \
    .config("spark.executor.memory", "4g") \
    .config("spark.sql.shuffle.partitions", "50") \
    .getOrCreate()
```

### Logs pour le Debugging

```bash
# Logs Django
tail -f /home/kevyn-odjo/Documents/T-DAT/logs/django.log

# Logs Spark Ingestion
tail -f /home/kevyn-odjo/Documents/T-DAT/logs/spark_ingestion.log

# Logs Spark Analytics
tail -f /home/kevyn-odjo/Documents/T-DAT/logs/spark_analytics.log

# Logs TimescaleDB
docker logs -f crypto_viz_timescaledb

# Logs Redis
docker logs -f crypto_viz_redis
```

### Nettoyage Complet (dernier recours)

```bash
cd /home/kevyn-odjo/Documents/T-DAT

# Arr√™ter tous les services
./scripts/stop_all.sh

# Supprimer les environnements virtuels
rm -rf crypto_viz_backend/venv
rm -rf spark_jobs/venv

# Supprimer la base SQLite
rm -rf crypto_viz_backend/db.sqlite3

# Supprimer les volumes Docker
docker compose down -v

# Supprimer les checkpoints Spark
rm -rf /tmp/spark_checkpoints/*

# Supprimer les logs
rm -rf logs/*.log logs/*.pid

# R√©installer
./scripts/setup_project.sh
```

---

## üìû Obtenir de l'Aide

### Avant de demander de l'aide

1. **V√©rifier les logs** (voir section ci-dessus)
2. **Tester les connexions** :
   ```bash
   python3 scripts/test_kafka_connection.py
   python3 scripts/test_timescale_connection.py
   curl http://localhost:8000/api/v1/health/
   ```
3. **V√©rifier l'√©tat des services** :
   ```bash
   docker compose ps
   ps aux | grep python
   ```

### Informations utiles √† fournir

- Version de Python : `python3 --version`
- Version de Docker : `docker --version`
- Version de Java : `java -version`
- Syst√®me d'exploitation : `uname -a`
- Logs d'erreur complets
- Commandes ex√©cut√©es avant l'erreur

---

## ‚úÖ Checklist de V√©rification

Avant de d√©marrer le projet, v√©rifier :

- [ ] Python 3.11+ install√©
- [ ] Docker install√© et d√©marr√©
- [ ] Java 11+ install√©
- [ ] Ports 15432, 6380, 8000 disponibles
- [ ] Serveur Kafka accessible (20.199.136.163:9092)
- [ ] Fichier .env configur√©
- [ ] D√©pendances Python install√©es (venv actif)
- [ ] TimescaleDB initialis√©

---

**Pour plus d'informations** :
- [README.md](./README.md)
- [INSTALLATION.md](./INSTALLATION.md)
- [QUICKSTART.md](./QUICKSTART.md)
