# ğŸš€ Configuration Kafka Locale - ImplÃ©mentation ComplÃ¨te

## âœ… Changements ImplÃ©mentÃ©s

Suite Ã  l'analyse du dÃ©pÃ´t [T-DAT-1](https://github.com/Izzoudine/T-DAT-1), le projet utilise maintenant **Kafka + Zookeeper locaux** au lieu d'un serveur Kafka distant.

---

## ğŸ“‹ Approche T-DAT-1 AdoptÃ©e

### **Principe**
- **Kafka et Zookeeper** dÃ©ployÃ©s localement via Docker Compose
- **CrÃ©ation automatique des topics** via script au dÃ©marrage
- **Environnement auto-suffisant** - pas de dÃ©pendance externe
- **Configuration optimisÃ©e** pour dÃ©veloppement et production

### **Avantages**
âœ… ContrÃ´le total sur l'infrastructure  
âœ… ReproductibilitÃ© garantie  
âœ… Tests locaux simplifiÃ©s  
âœ… Pas de dÃ©pendance rÃ©seau externe  
âœ… Configuration flexible des topics  

---

## ğŸ”§ Modifications ApportÃ©es

### **1. Docker Compose** (`docker-compose.yml`)

**Ajout de 2 nouveaux services :**

```yaml
services:
  # Zookeeper pour Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    ports: 2181
    
  # Kafka pour streaming
  kafka:
    image: confluentinc/cp-kafka:7.7.0
    ports: 9092, 29092
    environment:
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
```

**Configuration Kafka :**
- **Port externe** : `localhost:9092` (accÃ¨s depuis l'hÃ´te)
- **Port interne** : `kafka:29092` (accÃ¨s depuis les conteneurs)
- **Auto-crÃ©ation dÃ©sactivÃ©e** : les topics sont crÃ©Ã©s manuellement via script

---

### **2. Script de CrÃ©ation de Topics** (`scripts/create_kafka_topics.sh`)

**Topics crÃ©Ã©s automatiquement :**
- `rawticker` - DonnÃ©es de prix en temps rÃ©el (3 partitions)
- `rawtrade` - Transactions/trades (3 partitions)
- `rawarticle` - Articles de presse crypto (3 partitions)
- `rawalert` - Alertes de marchÃ© (3 partitions)

**CaractÃ©ristiques :**
- Utilise `--if-not-exists` pour Ã©viter les erreurs
- Attend que Kafka soit complÃ¨tement dÃ©marrÃ© (retry logic)
- VÃ©rifie la crÃ©ation des topics

---

### **3. Configuration Mise Ã  Jour**

#### **`.env` et `.env.example`**
```bash
# AVANT
KAFKA_SERVERS=20.199.136.163:9092

# APRÃˆS
KAFKA_SERVERS=localhost:9092
```

#### **`spark_jobs/config.py`**
```python
# AVANT
KAFKA_BOOTSTRAP_SERVERS = os.environ.get('KAFKA_SERVERS', '20.199.136.163:9092')

# APRÃˆS
KAFKA_BOOTSTRAP_SERVERS = os.environ.get('KAFKA_SERVERS', 'localhost:9092')
```

---

### **4. Workflow de DÃ©marrage** (`scripts/start_all.sh`)

**Nouvelle sÃ©quence :**

```
1. DÃ©marrer Zookeeper + Kafka + TimescaleDB + Redis (40s d'attente)
2. CrÃ©er automatiquement les topics Kafka
3. Initialiser TimescaleDB
4. DÃ©marrer Django API
5. DÃ©marrer les jobs Spark (ingestion + analytics)
```

**DÃ©lai d'attente :**
- AugmentÃ© Ã  **40 secondes** (au lieu de 30s) pour stabilisation complÃ¨te de Kafka
- InspirÃ© de T-DAT-1 qui recommande 40s minimum

---

## ğŸ¯ Utilisation

### **DÃ©marrage Complet**

```bash
cd /home/kevyn-odjo/Documents/T-DAT

# DÃ©marrer tous les services
./scripts/start_all.sh
```

**Ce qui se passe :**
1. âœ… Zookeeper dÃ©marre et se stabilise
2. âœ… Kafka dÃ©marre et se connecte Ã  Zookeeper
3. âœ… Topics Kafka crÃ©Ã©s automatiquement (rawticker, rawtrade, rawarticle, rawalert)
4. âœ… TimescaleDB et Redis dÃ©marrent
5. âœ… Django API dÃ©marre avec migrations
6. âœ… Jobs Spark dÃ©marrent et se connectent Ã  Kafka local

### **VÃ©rification Kafka**

```bash
# VÃ©rifier que Kafka est actif
docker exec crypto_viz_kafka kafka-broker-api-versions --bootstrap-server kafka:29092

# Lister les topics
docker exec crypto_viz_kafka kafka-topics --bootstrap-server kafka:29092 --list

# Voir les dÃ©tails d'un topic
docker exec crypto_viz_kafka kafka-topics --bootstrap-server kafka:29092 --describe --topic rawticker
```

### **ArrÃªt**

```bash
./scripts/stop_all.sh
```

ArrÃªte tous les services : Spark, Django, Kafka, Zookeeper, TimescaleDB, Redis.

---

## ğŸ“Š Architecture Finale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CRYPTO VIZ STACK                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  [Producteurs de DonnÃ©es]  (Ã  implÃ©menter)         â”‚
â”‚       â”‚                                             â”‚
â”‚       â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  Kafka (port 9092)  â”‚  â—„â”€â”€ Topics:              â”‚
â”‚  â”‚  + Zookeeper (2181) â”‚      - rawticker          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      - rawtrade           â”‚
â”‚       â”‚                        - rawarticle         â”‚
â”‚       â–¼                        - rawalert           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚   Spark Jobs        â”‚                           â”‚
â”‚  â”‚  - Ingestion        â”‚                           â”‚
â”‚  â”‚  - Analytics        â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                             â”‚
â”‚       â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚ TimescaleDB (15432) â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                                             â”‚
â”‚       â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  Django API (8000)  â”‚                           â”‚
â”‚  â”‚  + Redis (6380)     â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Comparaison Avant/AprÃ¨s

| Aspect | Avant | AprÃ¨s |
|--------|-------|-------|
| **Kafka** | Serveur distant (20.199.136.163) | Local Docker (localhost:9092) |
| **Topics** | Devaient exister sur serveur distant | CrÃ©Ã©s automatiquement au dÃ©marrage |
| **DÃ©pendances** | Serveur Kafka externe requis | Auto-suffisant |
| **ReproductibilitÃ©** | Difficile (dÃ©pend du serveur) | Facile (tout en Docker) |
| **Configuration** | Fixe | Flexible et modifiable |
| **ProblÃ¨mes** | Topics manquants â†’ Ã©chec Spark | Tous les topics crÃ©Ã©s automatiquement |

---

## âš™ï¸ Configuration AvancÃ©e

### **Modifier les Topics**

Ã‰ditez `scripts/create_kafka_topics.sh` :

```bash
# Ajouter un nouveau topic
TOPICS=(
    "rawticker"
    "rawtrade"
    "rawarticle"
    "rawalert"
    "mon_nouveau_topic"  # â† Nouveau
)

# Modifier le nombre de partitions
PARTITIONS=5  # Au lieu de 3
```

### **Ajuster les Ressources Kafka**

Dans `docker-compose.yml` :

```yaml
kafka:
  environment:
    KAFKA_HEAP_OPTS: "-Xmx2G -Xms2G"  # Plus de mÃ©moire
  mem_limit: 2.5g
```

---

## ğŸ› DÃ©pannage

### **Kafka ne dÃ©marre pas**

```bash
# VÃ©rifier les logs
docker logs crypto_viz_kafka

# Augmenter le dÃ©lai d'attente dans start_all.sh
sleep 60  # Au lieu de 40
```

### **Topics non crÃ©Ã©s**

```bash
# CrÃ©er manuellement
./scripts/create_kafka_topics.sh

# Ou individuellement
docker exec crypto_viz_kafka kafka-topics \
  --bootstrap-server kafka:29092 \
  --create --topic rawticker \
  --partitions 3 --replication-factor 1
```

### **Spark ne se connecte pas Ã  Kafka**

```bash
# VÃ©rifier la connexion
nc -zv localhost 9092

# VÃ©rifier la config Spark
cat spark_jobs/config.py | grep KAFKA
```

---

## ğŸ“š Ressources

- **DÃ©pÃ´t T-DAT-1** : https://github.com/Izzoudine/T-DAT-1
- **Confluent Kafka Docker** : https://docs.confluent.io/platform/current/installation/docker/
- **Spark Kafka Integration** : https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html

---

## âœ¨ Prochaines Ã‰tapes

1. **ImplÃ©menter les producteurs de donnÃ©es** (websocket Kraken, scraping articles)
2. **Tester le flux complet** : Producteur â†’ Kafka â†’ Spark â†’ TimescaleDB â†’ Django API
3. **Ajouter des mÃ©triques** de monitoring Kafka
4. **Configurer la persistance** des donnÃ©es Kafka (actuellement en volume Docker)

---

**Date de crÃ©ation** : 20 janvier 2026  
**InspirÃ© de** : T-DAT-1 par Izzoudine  
**Statut** : âœ… ImplÃ©mentÃ© et prÃªt Ã  tester
