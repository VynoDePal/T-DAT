# âš ï¸ Configuration Kafka Requise

## Statut Actuel des Services

| Service | Statut | DÃ©tails |
|---------|--------|---------|
| **Django API** | âœ… OPÃ‰RATIONNEL | Migrations appliquÃ©es, API fonctionnelle |
| **TimescaleDB** | âœ… OPÃ‰RATIONNEL | Port 15432, prÃªt Ã  recevoir des donnÃ©es |
| **Redis** | âœ… OPÃ‰RATIONNEL | Port 6380 |
| **Spark Ingestion** | âŒ BLOQUÃ‰ | Topics Kafka introuvables |
| **Spark Analytics** | âŒ BLOQUÃ‰ | DÃ©pend de Spark Ingestion |

---

## ðŸ”´ ProblÃ¨me Principal : Topics Kafka Manquants

### Erreur ObservÃ©e

```
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: 
This server does not host this topic-partition.
```

### Cause

Les topics Kafka requis par l'application **n'existent pas** sur le serveur `20.199.136.163:9092`.

**Topics requis** :
- `rawticker` - DonnÃ©es de prix en temps rÃ©el
- `rawtrade` - Transactions/trades
- `rawarticle` - Articles de presse crypto
- `rawalert` - Alertes de marchÃ©

---

## âœ… Solutions

### Option 1 : CrÃ©er les Topics Kafka (RECOMMANDÃ‰)

Si vous avez accÃ¨s au serveur Kafka :

```bash
# Se connecter au serveur Kafka
ssh user@20.199.136.163

# CrÃ©er les topics
kafka-topics.sh --create \
  --topic rawticker \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1

kafka-topics.sh --create \
  --topic rawtrade \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1

kafka-topics.sh --create \
  --topic rawarticle \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1

kafka-topics.sh --create \
  --topic rawalert \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1
```

**VÃ©rifier** :
```bash
kafka-topics.sh --list --bootstrap-server localhost:9092
```

---

### Option 2 : Demander Ã  l'Administrateur

Si vous n'avez pas accÃ¨s au serveur Kafka, contactez l'administrateur systÃ¨me et demandez :

> "Bonjour, j'ai besoin de 4 topics Kafka sur le serveur 20.199.136.163:9092 pour mon application :
> - rawticker
> - rawtrade
> - rawarticle
> - rawalert
> 
> Configuration suggÃ©rÃ©e : 3 partitions, replication-factor 1"

---

### Option 3 : Mode DÃ©veloppement Local

Pour dÃ©velopper sans serveur Kafka distant, installez Kafka localement :

```bash
# Ubuntu/Debian
sudo apt-get install kafka

# Ou avec Docker
docker run -d \
  --name kafka \
  -p 9092:9092 \
  -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
  confluentinc/cp-kafka:latest
```

Puis modifiez `.env` :
```bash
KAFKA_SERVERS=localhost:9092
```

---

## ðŸ“‹ VÃ©rification

AprÃ¨s avoir crÃ©Ã© les topics :

```bash
# VÃ©rifier la connexion
./scripts/check_kafka_topics.sh

# Relancer les services
./scripts/stop_all.sh
./scripts/start_all.sh

# VÃ©rifier les logs
tail -f logs/spark_ingestion.log
```

**Logs attendus** :
```
DÃ©marrage du traitement du stream TICKER...
DÃ©marrage du traitement du stream TRADE...
DÃ©marrage du traitement du stream ARTICLE...
DÃ©marrage du traitement du stream ALERT...
Tous les streams sont actifs!
```

---

## ðŸŽ¯ Prochaines Ã‰tapes

**Une fois les topics crÃ©Ã©s** :

1. âœ… Les jobs Spark se connecteront automatiquement
2. âœ… Les donnÃ©es Kafka seront Ã©crites dans TimescaleDB
3. âœ… L'API Django pourra servir les donnÃ©es historiques
4. âœ… Le systÃ¨me sera pleinement opÃ©rationnel

---

## ðŸ“ž Besoin d'Aide ?

**VÃ©rifier l'Ã©tat actuel** :
```bash
# Services Docker
docker compose ps

# Connexion Kafka
nc -zv 20.199.136.163 9092

# API Django
curl http://localhost:8000/api/v1/health/

# Logs
tail -f logs/*.log
```

**Diagnostic complet** :
```bash
./scripts/diagnostic.sh
```

---

**Date de crÃ©ation** : 28 novembre 2024  
**DerniÃ¨re mise Ã  jour** : 28 novembre 2024
