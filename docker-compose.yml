services:
  # Zookeeper pour Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    ports:
      - "7072:7072"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: "-Xmx512M -Xms512M -javaagent:/usr/share/jmx_exporter/jmx_prometheus_javaagent.jar=7072:/usr/share/jmx_exporter/zookeeper.yml"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 768M
        reservations:
          cpus: '0.25'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - ./monitoring/jmx-exporter:/usr/share/jmx_exporter:ro
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Kafka pour streaming de données
  kafka:
    image: confluentinc/cp-kafka:7.7.0
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9101:9101"
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      # Performance optimizations
      KAFKA_COMPRESSION_TYPE: 'lz4'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_CLEANUP_POLICY: 'delete'
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
      # JMX Configuration pour monitoring
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: kafka
      KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka -Dcom.sun.management.jmxremote.rmi.port=9101"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1536M
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - kafka_data:/var/lib/kafka/data
      - ./monitoring/jmx-exporter:/usr/share/jmx_exporter:ro
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 29092 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  # TimescaleDB pour les séries temporelles
  timescaledb:
    image: timescale/timescaledb:latest-pg18
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-crypto_viz_ts}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
    ports:
      - "15432:5432"
    volumes:
      - timescale_data:/var/lib/postgresql/data
      - ./database/timescaledb_setup.sql:/docker-entrypoint-initdb.d/init.sql
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis pour Django Channels (optionnel)
  redis:
    image: redis:8-alpine
    ports:
      - "6380:6379"
    volumes:
      - redis_data:/data
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.125'
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Backend Django
  django:
    build: ./crypto_viz_backend
    command: >
      sh -c "python manage.py migrate &&
             python manage.py collectstatic --noinput &&
             python manage.py createsuperuser --noinput --username admin --email admin@cryptoviz.com || true &&
             gunicorn crypto_viz.wsgi:application --bind 0.0.0.0:8000 --workers 2 --threads 4 --worker-class gthread --worker-tmp-dir /dev/shm"
    environment:
      - DEBUG=${DEBUG:-True}
      - KAFKA_SERVERS=kafka:29092
      - TIMESCALE_DB_HOST=timescaledb
      - TIMESCALE_DB_NAME=${POSTGRES_DB:-crypto_viz_ts}
      - TIMESCALE_DB_USER=${POSTGRES_USER:-postgres}
      - TIMESCALE_DB_PASSWORD=${POSTGRES_PASSWORD:-password}
      - REDIS_HOST=redis
      - DJANGO_SUPERUSER_USERNAME=${DJANGO_SUPERUSER_USERNAME:-admin}
      - DJANGO_SUPERUSER_EMAIL=${DJANGO_SUPERUSER_EMAIL:-admin@cryptoviz.com}
      - DJANGO_SUPERUSER_PASSWORD=${DJANGO_SUPERUSER_PASSWORD:-admin}
    ports:
      - "8000:8000"
    volumes:
      - ./crypto_viz_backend:/app
      - static_data:/app/staticfiles
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      kafka:
        condition: service_healthy
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  # Prometheus pour monitoring
  prometheus:
    image: prom/prometheus:v2.55.0
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus:/etc/prometheus:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.enable-lifecycle'
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    restart: unless-stopped

  # Grafana pour visualisation
  grafana:
    image: grafana/grafana:11.3.0
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=${GRAFANA_ROOT_URL:-http://localhost:3000}
      - GF_SECURITY_COOKIE_SECURE=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      - prometheus
    restart: unless-stopped

  # Kafka Exporter pour métriques consommateurs
  kafka-exporter:
    image: danielqsj/kafka-exporter:v1.8.0
    ports:
      - "9308:9308"
    command:
      - '--kafka.server=kafka:29092'
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.125'
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"
    depends_on:
      kafka:
        condition: service_healthy
    restart: unless-stopped

  # Node Exporter pour métriques système
  node-exporter:
    image: prom/node-exporter:v1.8.2
    ports:
      - "9100:9100"
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 64M
        reservations:
          cpus: '0.125'
          memory: 32M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    restart: unless-stopped

  # Redis Exporter pour métriques Redis
  redis-exporter:
    image: oliver006/redis_exporter:v1.67.0
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis:6379
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 64M
        reservations:
          cpus: '0.125'
          memory: 32M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

  # Postgres Exporter pour métriques TimescaleDB
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.16.0
    ports:
      - "9187:9187"
    environment:
      - DATA_SOURCE_NAME=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-password}@timescaledb:5432/${POSTGRES_DB:-crypto_viz_ts}?sslmode=disable
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.125'
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"
    depends_on:
      timescaledb:
        condition: service_healthy
    restart: unless-stopped

volumes:
  zookeeper_data:
  kafka_data:
  timescale_data:
  redis_data:
  static_data:
  prometheus_data:
  grafana_data:
