services:
  # Zookeeper pour Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka pour streaming de données
  kafka:
    image: confluentinc/cp-kafka:7.7.0
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9101:9101"
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      # Performance optimizations
      KAFKA_COMPRESSION_TYPE: 'lz4'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_CLEANUP_POLICY: 'delete'
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 29092 || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 20
      start_period: 60s

  # TimescaleDB pour les séries temporelles
  timescaledb:
    image: timescale/timescaledb:latest-pg16
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-crypto_viz_ts}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
    ports:
      - "15432:5432"
    volumes:
      - timescale_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  # Redis pour Django Channels (optionnel)
  redis:
    image: redis:8-alpine
    ports:
      - "6380:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Service d'initialisation Kafka (création des topics)
  kafka-init:
    image: confluentinc/cp-kafka:7.7.0
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      bash -c "
        echo 'Attente de Kafka...' &&
        sleep 10 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_tickers --partitions 3 --replication-factor 1 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_trades --partitions 3 --replication-factor 1 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_articles --partitions 3 --replication-factor 1 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_alerts --partitions 3 --replication-factor 1 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_sentiment --partitions 3 --replication-factor 1 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_predictions --partitions 3 --replication-factor 1 &&
        echo 'Topics Kafka créés avec succès!'
      "
    restart: "no"

  # Backend Django
  django:
    build: ./crypto_viz_backend
    command: >
      sh -c "python manage.py migrate &&
             python manage.py collectstatic --noinput &&
             python manage.py createsuperuser --noinput --username admin --email admin@cryptoviz.com || true &&
             gunicorn crypto_viz.wsgi:application --bind 0.0.0.0:8000"
    environment:
      - DEBUG=${DEBUG:-True}
      - KAFKA_SERVERS=kafka:29092
      - TIMESCALE_DB_HOST=timescaledb
      - TIMESCALE_DB_NAME=${POSTGRES_DB:-crypto_viz_ts}
      - TIMESCALE_DB_USER=${POSTGRES_USER:-postgres}
      - TIMESCALE_DB_PASSWORD=${POSTGRES_PASSWORD:-password}
      - REDIS_HOST=redis
      - DJANGO_SUPERUSER_USERNAME=${DJANGO_SUPERUSER_USERNAME:-admin}
      - DJANGO_SUPERUSER_EMAIL=${DJANGO_SUPERUSER_EMAIL:-admin@cryptoviz.com}
      - DJANGO_SUPERUSER_PASSWORD=${DJANGO_SUPERUSER_PASSWORD:-admin}
    ports:
      - "8000:8000"
    volumes:
      - static_data:/app/staticfiles
    depends_on:
      kafka:
        condition: service_healthy
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy

volumes:
  zookeeper_data:
  kafka_data:
  timescale_data:
  redis_data:
  static_data:
