services:
  # Zookeeper pour Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka pour streaming de données
  kafka:
    image: confluentinc/cp-kafka:7.7.0
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9101:9101"
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      # Performance optimizations
      KAFKA_COMPRESSION_TYPE: 'lz4'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_CLEANUP_POLICY: 'delete'
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 29092 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  # TimescaleDB pour les séries temporelles
  timescaledb:
    image: timescale/timescaledb:latest-pg16
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-crypto_viz_ts}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
    ports:
      - "15432:5432"
    volumes:
      - timescale_data:/var/lib/postgresql/data
      - type: bind
        source: ./init-timescale.sql
        target: /docker-entrypoint-initdb.d/init.sql
        content: |
          -- Script d'initialisation TimescaleDB pour CRYPTO VIZ
          CREATE EXTENSION IF NOT EXISTS timescaledb;
          
          -- Table ticker_data
          CREATE TABLE IF NOT EXISTS ticker_data (
              timestamp TIMESTAMPTZ NOT NULL,
              pair VARCHAR(20) NOT NULL,
              last DOUBLE PRECISION NOT NULL,
              bid DOUBLE PRECISION,
              ask DOUBLE PRECISION,
              volume_24h DOUBLE PRECISION
          );
          SELECT create_hypertable('ticker_data', 'timestamp', if_not_exists => TRUE);
          CREATE INDEX IF NOT EXISTS idx_ticker_pair_timestamp ON ticker_data (pair, timestamp DESC);
          
          -- Table trade_data
          CREATE TABLE IF NOT EXISTS trade_data (
              timestamp TIMESTAMPTZ NOT NULL,
              pair VARCHAR(20) NOT NULL,
              price DOUBLE PRECISION NOT NULL,
              volume DOUBLE PRECISION NOT NULL,
              side VARCHAR(1) NOT NULL
          );
          SELECT create_hypertable('trade_data', 'timestamp', if_not_exists => TRUE);
          CREATE INDEX IF NOT EXISTS idx_trade_pair_timestamp ON trade_data (pair, timestamp DESC);
          
          -- Table article_data
          CREATE TABLE IF NOT EXISTS article_data (
              timestamp TIMESTAMPTZ NOT NULL,
              article_id VARCHAR(255) NOT NULL,
              title TEXT NOT NULL,
              url TEXT NOT NULL,
              website VARCHAR(100),
              summary TEXT,
              cryptocurrencies_mentioned TEXT[],
              sentiment_score DOUBLE PRECISION,
              sentiment_label VARCHAR(20)
          );
          SELECT create_hypertable('article_data', 'timestamp', if_not_exists => TRUE);
          
          -- Table alert_data
          CREATE TABLE IF NOT EXISTS alert_data (
              timestamp TIMESTAMPTZ NOT NULL,
              pair VARCHAR(20) NOT NULL,
              last_price DOUBLE PRECISION NOT NULL,
              change_percent DOUBLE PRECISION NOT NULL,
              threshold DOUBLE PRECISION NOT NULL,
              alert_type VARCHAR(20) NOT NULL
          );
          SELECT create_hypertable('alert_data', 'timestamp', if_not_exists => TRUE);
          
          -- Table sentiment_data
          CREATE TABLE IF NOT EXISTS sentiment_data (
              timestamp TIMESTAMPTZ NOT NULL,
              crypto_symbol VARCHAR(10) NOT NULL,
              sentiment_score DOUBLE PRECISION NOT NULL,
              sentiment_label VARCHAR(20) NOT NULL,
              source VARCHAR(100) NOT NULL,
              confidence DOUBLE PRECISION
          );
          SELECT create_hypertable('sentiment_data', 'timestamp', if_not_exists => TRUE);
          
          -- Table prediction_data
          CREATE TABLE IF NOT EXISTS prediction_data (
              timestamp TIMESTAMPTZ NOT NULL,
              crypto_symbol VARCHAR(10) NOT NULL,
              predicted_price DOUBLE PRECISION NOT NULL,
              actual_price DOUBLE PRECISION,
              model_name VARCHAR(50) NOT NULL,
              confidence_interval_low DOUBLE PRECISION,
              confidence_interval_high DOUBLE PRECISION
          );
          SELECT create_hypertable('prediction_data', 'timestamp', if_not_exists => TRUE);
          
          -- Politiques de rétention (90 jours)
          SELECT add_retention_policy('ticker_data', INTERVAL '90 days', if_not_exists => TRUE);
          SELECT add_retention_policy('trade_data', INTERVAL '90 days', if_not_exists => TRUE);
          SELECT add_retention_policy('article_data', INTERVAL '90 days', if_not_exists => TRUE);
          SELECT add_retention_policy('alert_data', INTERVAL '90 days', if_not_exists => TRUE);
          SELECT add_retention_policy('sentiment_data', INTERVAL '90 days', if_not_exists => TRUE);
          SELECT add_retention_policy('prediction_data', INTERVAL '90 days', if_not_exists => TRUE);
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis pour Django Channels (optionnel)
  redis:
    image: redis:8-alpine
    ports:
      - "6380:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Service d'initialisation Kafka (création des topics)
  kafka-init:
    image: confluentinc/cp-kafka:7.7.0
    exclude_from_hc: true
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      bash -c "
        echo 'Attente de Kafka...' &&
        sleep 10 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_tickers --partitions 3 --replication-factor 1 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_trades --partitions 3 --replication-factor 1 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_articles --partitions 3 --replication-factor 1 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_alerts --partitions 3 --replication-factor 1 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_sentiment --partitions 3 --replication-factor 1 &&
        kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic crypto_predictions --partitions 3 --replication-factor 1 &&
        echo 'Topics Kafka créés avec succès!'
      "
    restart: "no"

  # Backend Django
  django:
    build: ./crypto_viz_backend
    command: >
      sh -c "python manage.py migrate &&
             python manage.py collectstatic --noinput &&
             python manage.py createsuperuser --noinput --username admin --email admin@cryptoviz.com || true &&
             gunicorn crypto_viz.wsgi:application --bind 0.0.0.0:8000"
    environment:
      - DEBUG=${DEBUG:-True}
      - KAFKA_SERVERS=kafka:29092
      - TIMESCALE_DB_HOST=timescaledb
      - TIMESCALE_DB_NAME=${POSTGRES_DB:-crypto_viz_ts}
      - TIMESCALE_DB_USER=${POSTGRES_USER:-postgres}
      - TIMESCALE_DB_PASSWORD=${POSTGRES_PASSWORD:-password}
      - REDIS_HOST=redis
      - DJANGO_SUPERUSER_USERNAME=${DJANGO_SUPERUSER_USERNAME:-admin}
      - DJANGO_SUPERUSER_EMAIL=${DJANGO_SUPERUSER_EMAIL:-admin@cryptoviz.com}
      - DJANGO_SUPERUSER_PASSWORD=${DJANGO_SUPERUSER_PASSWORD:-admin}
    ports:
      - "8000:8000"
    volumes:
      - static_data:/app/staticfiles
    depends_on:
      kafka:
        condition: service_healthy
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy

volumes:
  zookeeper_data:
  kafka_data:
  timescale_data:
  redis_data:
  static_data:
